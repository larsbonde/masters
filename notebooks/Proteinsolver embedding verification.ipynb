{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873ff6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/home/sebastian/masters/') # add my repo to python path\n",
    "import os\n",
    "import torch\n",
    "import torch_geometric\n",
    "import kmbio  # fork of biopython PDB with some changes in how the structure, chain, etc. classes are defined.\n",
    "import numpy as np\n",
    "import proteinsolver\n",
    "import modules\n",
    "from modules.dataset import *\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cdde1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_file = \"/home/sebastian/data/e53-s1952148-d93703104.state\"\n",
    "root = \"/home/sebastian/masters/data/210916_TCRpMHCmodels/\"\n",
    "save_path = \"/home/sebastian/masters/data/trained_models/test_model.state\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2616d",
   "metadata": {},
   "source": [
    "### Load positive examples and split into structure configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b946a100",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2078894121.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_29109/2078894121.py\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    for each file:\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class ChainFilter(kmbio.PDB.Select):\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "\n",
    "    def accept_chain(self, chain):\n",
    "        if chain.id in self.subset:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "raw_files, targets = get_data(\n",
    "    model_dir=f\"{root}/models/\",\n",
    "    model_name=f\"model_TCR-pMHC.pdb\",\n",
    "    metadata=f\"{root}/train_data_gene_names.csv\",\n",
    ")\n",
    "pos_raw_files = np.ma.masked_array(raw_files, mask=targets)  # only get positives\n",
    "\n",
    "pmhc_chain_subset = [\"M\", \"P\"]\n",
    "p_chain_subset = [\"P\"]\n",
    "\n",
    "for raw_file in pos_raw_files:\n",
    "    \n",
    "    common_path = os.path.dirname(raw_file)\n",
    "    pmhc_file_name = f\"{common_path}/model_pMHC.pdb\"\n",
    "    p_file_name =  f\"{common_path}/model_p.pdb\"\n",
    "    \n",
    "    structure  = kmbio.PDB.load(raw_file)\n",
    "    \n",
    "    io = kmbio.PDB.io.PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(pmhc_file_name, ChainFilter(subset=pmhc_chain_subset))\n",
    "    \n",
    "    io = kmbio.PDB.io.PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    io.save(p_file_name, ChainFilter(subset=p_chain_subset))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#for each file:\n",
    "#    load into bio pdb\n",
    "#    make new structures for the two new configs (one config is just the normal, so 3 total)\n",
    "#    save the new structures in some folder if not already present\n",
    "#    add each 3 paths to 3 list (i.e. a list with files for each config)\n",
    "#\n",
    "#pass each list to normal data and make pre process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf53cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_files, targets = get_data(\n",
    "    model_dir=f\"{root}/models/\",\n",
    "    model_name=f\"model_TCR-pMHC.pdb\",\n",
    "    metadata=f\"{root}/train_data_gene_names.csv\",\n",
    ")\n",
    "\n",
    "targets = targets[targets]\n",
    "pos_binders = raw_files[targets]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# make quick data split\n",
    "n_data = len(raw_files)\n",
    "valid_frac = 0.1\n",
    "valid_num = int(n_data * valid_frac)\n",
    "selection = np.random.randint(0, n_data, valid_num)\n",
    "mask = np.zeros(n_data, bool)\n",
    "mask[selection] = 1\n",
    "\n",
    "valid_files = raw_files[mask]\n",
    "valid_targets = targets[mask]\n",
    "d_valid = ProteinDataset(f\"{root}/valid\", valid_files, valid_targets, overwrite=True)\n",
    "\n",
    "train_files = raw_files[~mask]\n",
    "train_targets = targets[~mask]\n",
    "d_train = ProteinDataset(f\"{root}/train\", train_files, train_targets, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391919ad",
   "metadata": {},
   "source": [
    "### Generate datasets for different structure configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00401650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
