{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6552d90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5ff002b6f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/home/sebastian/masters/') # add my repo to python path\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import kmbio  # fork of biopython PDB with some changes in how the structure, chain, etc. classes are defined.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import proteinsolver\n",
    "import modules\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, BatchSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import *\n",
    "from torch import nn, optim\n",
    "from pathlib import Path\n",
    "\n",
    "from modules.dataset_utils import *\n",
    "from modules.dataset import *\n",
    "from modules.utils import *\n",
    "from modules.models import *\n",
    "from modules.lstm_utils import *\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c0bded",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c8ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"/home/sebastian/masters/data/\")\n",
    "data_root = root / \"neat_data\"\n",
    "metadata_path = data_root / \"metadata.csv\"\n",
    "processed_dir = data_root / \"processed\"\n",
    "state_file = root / \"state_files\" / \"e53-s1952148-d93703104.state\"\n",
    "out_dir = root / \"state_files\" / \"tcr_binding\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e550ed",
   "metadata": {},
   "source": [
    "### Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8d579c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#ID</th>\n",
       "      <th>CDR3a</th>\n",
       "      <th>CDR3b</th>\n",
       "      <th>peptide</th>\n",
       "      <th>partition</th>\n",
       "      <th>binder</th>\n",
       "      <th>v_gene_alpha</th>\n",
       "      <th>j_gene_alpha</th>\n",
       "      <th>v_gene_beta</th>\n",
       "      <th>j_gene_beta</th>\n",
       "      <th>origin</th>\n",
       "      <th>v_alpha_vdjdb_name</th>\n",
       "      <th>j_alpha_vdjdb_name</th>\n",
       "      <th>v_beta_vdjdb_name</th>\n",
       "      <th>j_beta_vdjdb_name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AVSQSNTGKLI</td>\n",
       "      <td>ASSQLMENTEAF</td>\n",
       "      <td>NLVPMVATV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAV12-2</td>\n",
       "      <td>TRAJ37</td>\n",
       "      <td>TRBV4-1</td>\n",
       "      <td>TRBJ1-1</td>\n",
       "      <td>tenX</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>TRAJ37*01</td>\n",
       "      <td>TRBV4-1*01</td>\n",
       "      <td>TRBJ1-1*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AASEVCADYKLS</td>\n",
       "      <td>ASSYSLLRAAPNTEAF</td>\n",
       "      <td>NLVPMVATV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAV29DV5</td>\n",
       "      <td>TRAJ20</td>\n",
       "      <td>TRBV6-3</td>\n",
       "      <td>TRBJ1-1</td>\n",
       "      <td>tenX</td>\n",
       "      <td>TRAV29/DV5*01</td>\n",
       "      <td>TRAJ20*01</td>\n",
       "      <td>TRBV6-3*01</td>\n",
       "      <td>TRBJ1-1*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AGRLGAQKLV</td>\n",
       "      <td>ASSQGGRRNQPQH</td>\n",
       "      <td>NLVPMVATV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAV25</td>\n",
       "      <td>TRAJ54</td>\n",
       "      <td>TRBV4-2</td>\n",
       "      <td>TRBJ1-5</td>\n",
       "      <td>tenX</td>\n",
       "      <td>TRAV25*01</td>\n",
       "      <td>TRAJ54*01</td>\n",
       "      <td>TRBV4-2*01</td>\n",
       "      <td>TRBJ1-5*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AVEPLYGNKLV</td>\n",
       "      <td>ASSSREAEAF</td>\n",
       "      <td>NLVPMVATV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAV22</td>\n",
       "      <td>TRAJ47</td>\n",
       "      <td>TRBV7-9</td>\n",
       "      <td>TRBJ1-1</td>\n",
       "      <td>tenX</td>\n",
       "      <td>TRAV22*01</td>\n",
       "      <td>TRAJ47*01</td>\n",
       "      <td>TRBV7-9*01</td>\n",
       "      <td>TRBJ1-1*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ASGTYKYI</td>\n",
       "      <td>ASSQRAGRVDTQY</td>\n",
       "      <td>NLVPMVATV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAV19</td>\n",
       "      <td>TRAJ40</td>\n",
       "      <td>TRBV27</td>\n",
       "      <td>TRBJ2-3</td>\n",
       "      <td>tenX</td>\n",
       "      <td>TRAV19*01</td>\n",
       "      <td>TRAJ40*01</td>\n",
       "      <td>TRBV27*01</td>\n",
       "      <td>TRBJ2-3*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>12961</td>\n",
       "      <td>AVNSYYNQGGKLI</td>\n",
       "      <td>SVLQGSPYEQY</td>\n",
       "      <td>GILGFVFTL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>TRAJ23*01</td>\n",
       "      <td>TRBV29-1*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>TRAJ23*01</td>\n",
       "      <td>TRBV29-1*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10327</th>\n",
       "      <td>12962</td>\n",
       "      <td>AGNYGGSQGNLI</td>\n",
       "      <td>ASSIYSVNEQF</td>\n",
       "      <td>GILGFVFTL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAV35*01</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-1*01</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRAV35*01</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-1*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>12966</td>\n",
       "      <td>AVGGSQGNLI</td>\n",
       "      <td>ASSVRSSYEQY</td>\n",
       "      <td>GILGFVFTL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAV8-6*02</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRAV8-6*01</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329</th>\n",
       "      <td>12968</td>\n",
       "      <td>AENGGGGADGLT</td>\n",
       "      <td>ASSIRSSYEQY</td>\n",
       "      <td>GILGFVFTL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAV13-2*01</td>\n",
       "      <td>TRAJ45*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRAV13-2*01</td>\n",
       "      <td>TRAJ45*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10330</th>\n",
       "      <td>12971</td>\n",
       "      <td>AVSGSQGNLI</td>\n",
       "      <td>ASSLRSSYEQY</td>\n",
       "      <td>GILGFVFTL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAV8-6*02</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRAV8-6*01</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10331 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         #ID          CDR3a             CDR3b    peptide  partition  binder  \\\n",
       "0          1    AVSQSNTGKLI      ASSQLMENTEAF  NLVPMVATV          1       0   \n",
       "1          2   AASEVCADYKLS  ASSYSLLRAAPNTEAF  NLVPMVATV          1       0   \n",
       "2          3     AGRLGAQKLV     ASSQGGRRNQPQH  NLVPMVATV          1       0   \n",
       "3          4    AVEPLYGNKLV        ASSSREAEAF  NLVPMVATV          1       0   \n",
       "4          5       ASGTYKYI     ASSQRAGRVDTQY  NLVPMVATV          1       0   \n",
       "...      ...            ...               ...        ...        ...     ...   \n",
       "10326  12961  AVNSYYNQGGKLI       SVLQGSPYEQY  GILGFVFTL          1       1   \n",
       "10327  12962   AGNYGGSQGNLI       ASSIYSVNEQF  GILGFVFTL          1       1   \n",
       "10328  12966     AVGGSQGNLI       ASSVRSSYEQY  GILGFVFTL          1       1   \n",
       "10329  12968   AENGGGGADGLT       ASSIRSSYEQY  GILGFVFTL          1       1   \n",
       "10330  12971     AVSGSQGNLI       ASSLRSSYEQY  GILGFVFTL          1       1   \n",
       "\n",
       "      v_gene_alpha j_gene_alpha  v_gene_beta j_gene_beta    origin  \\\n",
       "0         TRAV12-2       TRAJ37      TRBV4-1     TRBJ1-1      tenX   \n",
       "1        TRAV29DV5       TRAJ20      TRBV6-3     TRBJ1-1      tenX   \n",
       "2           TRAV25       TRAJ54      TRBV4-2     TRBJ1-5      tenX   \n",
       "3           TRAV22       TRAJ47      TRBV7-9     TRBJ1-1      tenX   \n",
       "4           TRAV19       TRAJ40       TRBV27     TRBJ2-3      tenX   \n",
       "...            ...          ...          ...         ...       ...   \n",
       "10326  TRAV12-2*01    TRAJ23*01  TRBV29-1*01  TRBJ2-7*01  positive   \n",
       "10327    TRAV35*01    TRAJ42*01    TRBV19*01  TRBJ2-1*01  positive   \n",
       "10328   TRAV8-6*02    TRAJ42*01    TRBV19*01  TRBJ2-7*01  positive   \n",
       "10329  TRAV13-2*01    TRAJ45*01    TRBV19*01  TRBJ2-7*01  positive   \n",
       "10330   TRAV8-6*02    TRAJ42*01    TRBV19*01  TRBJ2-7*01  positive   \n",
       "\n",
       "      v_alpha_vdjdb_name  j_alpha_vdjdb_name  v_beta_vdjdb_name  \\\n",
       "0            TRAV12-2*01           TRAJ37*01         TRBV4-1*01   \n",
       "1          TRAV29/DV5*01           TRAJ20*01         TRBV6-3*01   \n",
       "2              TRAV25*01           TRAJ54*01         TRBV4-2*01   \n",
       "3              TRAV22*01           TRAJ47*01         TRBV7-9*01   \n",
       "4              TRAV19*01           TRAJ40*01          TRBV27*01   \n",
       "...                  ...                 ...                ...   \n",
       "10326        TRAV12-2*01           TRAJ23*01        TRBV29-1*01   \n",
       "10327          TRAV35*01           TRAJ42*01          TRBV19*01   \n",
       "10328         TRAV8-6*01           TRAJ42*01          TRBV19*01   \n",
       "10329        TRAV13-2*01           TRAJ45*01          TRBV19*01   \n",
       "10330         TRAV8-6*01           TRAJ42*01          TRBV19*01   \n",
       "\n",
       "       j_beta_vdjdb_name                                               path  \n",
       "0             TRBJ1-1*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "1             TRBJ1-1*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "2             TRBJ1-5*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "3             TRBJ1-1*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "4             TRBJ2-3*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "...                  ...                                                ...  \n",
       "10326         TRBJ2-7*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "10327         TRBJ2-1*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "10328         TRBJ2-7*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "10329         TRBJ2-7*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "10330         TRBJ2-7*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "\n",
       "[10331 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = data_root / \"raw\" / \"tcrpmhc\"\n",
    "\n",
    "paths = list(model_dir.glob(\"*\"))\n",
    "join_key = [int(x.name.split(\"_\")[0]) for x in paths]\n",
    "path_df = pd.DataFrame({'#ID': join_key, 'path': paths})\n",
    "\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "metadata = metadata.join(path_df.set_index(\"#ID\"), on=\"#ID\", how=\"inner\")  # filter to non-missing data\n",
    "metadata = metadata.reset_index(drop=True)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957a7f9a",
   "metadata": {},
   "source": [
    "i = 10326\n",
    "print(metadata.iloc[i])\n",
    "print(metadata.iloc[i][\"path\"])\n",
    "\n",
    "print(torch.load(f\"/home/sebastian/masters/data/neat_data/processed/tcr_binding/data_{i}.pt\"))\n",
    "print(torch.load(f\"/home/sebastian/masters/data/neat_data/processed/tcr_binding/data_{i}.pt\").y)\n",
    "\n",
    "print(torch.load(f\"/home/sebastian/masters/data/neat_data/processed/tcr_binding/gnn_out_pos_128/data_{i}.pt\").shape)\n",
    "print(targets[i])\n",
    "print(raw_files[i])\n",
    "print(dataset[i][0].shape, dataset[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c9a01",
   "metadata": {},
   "source": [
    "### Make GNN embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bec31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# init proteinsolver gnn\n",
    "num_features = 20\n",
    "adj_input_size = 2\n",
    "hidden_size = 128\n",
    "\n",
    "gnn = Net(\n",
    "    x_input_size=num_features + 1, \n",
    "    adj_input_size=adj_input_size, \n",
    "    hidden_size=hidden_size, \n",
    "    output_size=num_features\n",
    ")\n",
    "gnn.load_state_dict(torch.load(state_file, map_location=device))\n",
    "gnn.eval()\n",
    "gnn = gnn.to(device)\n",
    "\n",
    "raw_files = np.array(metadata[\"path\"])\n",
    "targets = np.array(metadata[\"binder\"])\n",
    "\n",
    "#dataset = ProteinDataset(processed_dir, raw_files, targets, overwrite=False)\n",
    "\n",
    "gnn_func = gnn.forward_without_last_layer\n",
    "out_dir = processed_dir / \"proteinsolver_preprocess\"\n",
    "#create_gnn_embeddings(dataset, out_dir, device, gnn_func, cores=4, overwrite=False)\n",
    "#create_gnn_embeddings(dataset, out_dir, device, gnn_func, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526dac04",
   "metadata": {},
   "source": [
    "### Make LOO partitions and init dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e368f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_train_partitions, loo_valid_partitions, val, unique_peptides = generate_3_loo_partitions(metadata)\n",
    "\n",
    "dataset = LSTMDataset(\n",
    "    data_dir=processed_dir / \"proteinsolver_embeddings_pos\", \n",
    "    annotations_path=processed_dir / \"proteinsolver_embeddings_pos\" / \"targets.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5f5ca",
   "metadata": {},
   "source": [
    "### LOO training scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2218fed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving to /home/sebastian/masters/data/neat_data/processed/proteinsolver_preprocess/34c185642b2f58ff00f303f61d4e6027\n",
      "Fold: 0\n",
      "Peptide: NLVPMVATV\n",
      "\n",
      "epoch: 1 - n: 61/953 - [=6%                                                         ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2922/910548204.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     net, train_losses, valid_losses = lstm_quad_train(\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/masters/modules/lstm_utils.py\u001b[0m in \u001b[0;36mlstm_quad_train\u001b[0;34m(model, epochs, criterion, optimizer, scheduler, dataset, train_idx, valid_idx, batch_size, device, collate_fn, early_stopping, extra_print)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LSTM params\n",
    "batch_size = 8\n",
    "embedding_dim = 128 + 4\n",
    "hidden_dim = 32 #32\n",
    "num_layers = 2  # from 2\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "lr_decay = 0.95\n",
    "w_decay = 1e-4\n",
    "dropout = 0.8  # test scheduled dropout. Can set droput using net.layer.dropout = 0.x https://arxiv.org/pdf/1703.06229.pdf\n",
    "\n",
    "# touch files to ensure output\n",
    "n_splits = len(unique_peptides)\n",
    "save_dir = get_non_dupe_dir(out_dir)\n",
    "loss_paths = touch_output_files(save_dir, \"loss\", n_splits)\n",
    "state_paths = touch_output_files(save_dir, \"state\", n_splits)\n",
    "pred_paths = touch_output_files(save_dir, \"pred\", n_splits)\n",
    "\n",
    "extra_print_str = \"\\nSaving to {}\\nFold: {}\\nPeptide: {}\"\n",
    "\n",
    "i = 0\n",
    "for train_idx, valid_idx in zip(loo_train_partitions, loo_valid_partitions):\n",
    "    \n",
    "    net = MyLSTM(\n",
    "        embedding_dim=embedding_dim, \n",
    "        hidden_dim=hidden_dim, \n",
    "        num_layers=num_layers, \n",
    "        dropout=dropout,\n",
    "    )\n",
    "    net = net.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        net.parameters(), \n",
    "        lr=learning_rate, \n",
    "        #weight_decay=w_decay,\n",
    "    )  # test learning rate scheduler to reduce validation volatility\n",
    "    scheduler = optim.lr_scheduler.MultiplicativeLR(\n",
    "        optimizer, \n",
    "        lr_lambda=lambda epoch: lr_decay\n",
    "    )\n",
    "    \n",
    "    net, train_losses, valid_losses = lstm_quad_train(\n",
    "        net,\n",
    "        epochs,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        dataset,\n",
    "        train_idx,\n",
    "        valid_idx,\n",
    "        batch_size,\n",
    "        device,\n",
    "        collate_fn=pad_collate,\n",
    "        extra_print=extra_print_str.format(save_dir, i, unique_peptides[i]),\n",
    "    )\n",
    "    torch.save(net.state_dict(), state_paths[i])\n",
    "    torch.save({\"train\": train_losses, \"valid\": valid_losses}, loss_paths[i])\n",
    "    \n",
    "    pred, true = lstm_quad_predict(net, dataset, valid_idx, device)     \n",
    "    torch.save({\"y_pred\": pred, \"y_true\": true}, pred_paths[i])\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce7995",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# LSTM params\n",
    "batch_size = 8\n",
    "embedding_dim = 128\n",
    "hidden_dim = 32 #32\n",
    "num_layers = 2  # from 2\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "lr_decay = 0.95\n",
    "w_decay = 1e-4\n",
    "dropout = 0.8  # test scheduled dropout. Can set droput using net.layer.dropout = 0.x https://arxiv.org/pdf/1703.06229.pdf\n",
    "\n",
    "# touch files to ensure output\n",
    "n_splits = len(unique_peptides)\n",
    "save_dir = get_non_dupe_dir(out_dir)\n",
    "loss_paths = touch_output_files(save_dir, \"loss\", n_splits)\n",
    "state_paths = touch_output_files(save_dir, \"state\", n_splits)\n",
    "pred_paths = touch_output_files(save_dir, \"pred\", n_splits)\n",
    "\n",
    "extra_print_str = \"\\nSaving to {}\\nFold: {}\\nPeptide: {}\"\n",
    "\n",
    "i = 0\n",
    "for train_idx, valid_idx in zip(loo_train_partitions, loo_valid_partitions):\n",
    "    \n",
    "    net = QuadLSTM(\n",
    "        embedding_dim=embedding_dim, \n",
    "        hidden_dim=hidden_dim, \n",
    "        num_layers=num_layers, \n",
    "        dropout=dropout,\n",
    "    )\n",
    "    net = net.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        net.parameters(), \n",
    "        lr=learning_rate, \n",
    "        #weight_decay=w_decay,\n",
    "    )  # test learning rate scheduler to reduce validation volatility\n",
    "    scheduler = optim.lr_scheduler.MultiplicativeLR(\n",
    "        optimizer, \n",
    "        lr_lambda=lambda epoch: lr_decay\n",
    "    )\n",
    "    \n",
    "    net, train_losses, valid_losses = lstm_quad_train(\n",
    "        net,\n",
    "        epochs,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        dataset,\n",
    "        train_idx,\n",
    "        valid_idx,\n",
    "        batch_size,\n",
    "        device,\n",
    "        extra_print=extra_print_str.format(save_dir, i, unique_peptides[i]),\n",
    "    )\n",
    "    torch.save(net.state_dict(), state_paths[i])\n",
    "    torch.save({\"train\": train_losses, \"valid\": valid_losses}, loss_paths[i])\n",
    "    \n",
    "    pred, true = lstm_quad_predict(net, dataset, valid_idx, device)     \n",
    "    torch.save({\"y_pred\": pred, \"y_true\": true}, pred_paths[i])\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493ea88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from io import StringIO \n",
    "import sys\n",
    "\n",
    "class Capturing(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio    # free up some memory\n",
    "        sys.stdout = self._stdout\n",
    "\n",
    "with Capturing() as output:\n",
    "    for _ in train_loader:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_f = open(\"/home/sebastian/masters/data/train_run.log\", \"r\")\n",
    "lines = err_f.readlines()\n",
    "lines = [line.strip() for line in lines]\n",
    "data = dict()\n",
    "prev_i = str()\n",
    "prev_mode = str()\n",
    "for line in lines:\n",
    "    if line[0] == \">\":\n",
    "        if line != \">train\" and line != \">pred\" and line != \">valid\":\n",
    "            prev_i = line[1:]\n",
    "            data[prev_i] = dict()\n",
    "        else:\n",
    "            prev_mode = line[1:]\n",
    "            data[prev_i][prev_mode] = list()\n",
    "    else:\n",
    "        try:\n",
    "            data[prev_i][prev_mode].append(int(line))\n",
    "        except ValueError as err:\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eddc4d",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "valid_pep = \"KTWGQYWQV\"\n",
    "#save_dir = Path(\"/home/sebastian/masters/data/state_files/tcr_binding/2nd_gen/proteinsolver_finetuning_es/60a15522a4f4418ac79b91af3ac55478//\")\n",
    "#save_dir = Path(\"/home/sebastian/masters/data/state_files/tcr_binding/2nd_gen/lstm_es/2947ef9a6aa76a87acb42a9c02594f54/\")\n",
    "save_dir = Path(\"/home/sebastian/masters/data/state_files/tcr_binding/2nd_gen/lstm_esm_ps/b3edafc0112356cefbdde3ca0ec5b396\")\n",
    "pred_paths = [save_dir / f\"pred_{i}.pt\" for i in range(len(unique_peptides))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fc225",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.load(save_dir/\"loss_0.pt\")\n",
    "plt.plot(t[\"train\"])\n",
    "plt.plot(t[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95690165",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd3586",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_splits = len(unique_peptides)\n",
    "threshold = 0.1\n",
    "\n",
    "overall_pred = list()\n",
    "overall_true = list()\n",
    "overall_thres_pred = list()\n",
    "# compute metrics\n",
    "perf_data = dict()\n",
    "for i in range(n_splits):\n",
    "    data = torch.load(pred_paths[i])\n",
    "    pred = data[\"y_pred\"]\n",
    "    true = data[\"y_true\"]\n",
    "\n",
    "    # auc\n",
    "    auc = roc_auc_score(true, pred)\n",
    "    fpr, tpr, thr = roc_curve(true, pred, pos_label=1)\n",
    "    \n",
    "    thresh_pred = torch.zeros(len(pred))\n",
    "    thresh_pred[pred >= threshold] = 1\n",
    "    mcc = matthews_corrcoef(true, thresh_pred)\n",
    "    \n",
    "    pep = unique_peptides[i]\n",
    "    perf_data[pep] = [fpr, tpr, auc, mcc]\n",
    "\n",
    "    print(auc, mcc)\n",
    "\n",
    "    overall_pred.extend(pred)\n",
    "    overall_true.extend(true)\n",
    "    overall_thres_pred.extend(thresh_pred)\n",
    "\n",
    "print(\"overall AUC:\", roc_auc_score(overall_true, overall_pred))  \n",
    "print(f\"overall MCC (t={threshold}):\", matthews_corrcoef(overall_true, overall_thres_pred))\n",
    "\n",
    "performance_file = save_dir / \"performance_data.pt\"\n",
    "torch.save(perf_data, performance_file)\n",
    "\n",
    "# ROC plot\n",
    "cm = plt.get_cmap('tab20')  # https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_prop_cycle(color=[cm(1*i/n_splits) for i in range(n_splits)])\n",
    "excluded = [\"KLQCVDLHV\", \"KVAELVHFL\", \"YLLEMLWRL\", \"SLLMWITQV\"] # TODO delete (filter <40 in test set)\n",
    "for pep in unique_peptides:\n",
    "    if pep not in excluded:\n",
    "        ax.plot(\n",
    "            perf_data[pep][0], \n",
    "            perf_data[pep][1], \n",
    "            label=f\"{pep}, AUC = {round(perf_data[pep][2], 3)}\",\n",
    "        )\n",
    "plt.legend()\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"LOO validation ROC curve (peptides with count < 40 left out for visual clarity (drop on CDR3b))\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be63300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28884af",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.load(save_dir/\"pred_4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[\"y_true\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31136322",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[\"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_df = metadata[metadata[\"peptide\"] == unique_peptides[4]]\n",
    "pep_df = pep_df.reset_index()\n",
    "pep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9434660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=-7\n",
    "metadata[metadata[\"CDR3a\"] == pep_df.iloc[i][\"CDR3a\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78884a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t[\"y_pred\"][i], t[\"y_true\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(t[\"y_pred\"], bins=len(t[\"y_pred\"]))\n",
    "plt.xlabel(\"score\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"distribution of pred scores for KVLEYVIKV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b93e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metadata[metadata[\"peptide\"] == unique_peptides[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f60068",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(t[\"y_true\"], t[\"y_pred\"], drop_intermediate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d149ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea22475",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd93896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "labels = [\"non-binder\", \"binder\"]\n",
    "pred_copy = copy.deepcopy(pred)\n",
    "pred_copy[pred >= 0.2] = 1\n",
    "pred_copy[pred < 0.2] = 0\n",
    "cm = confusion_matrix(true, pred_copy)\n",
    "\n",
    "# f1\n",
    "f1 = f1_score(true, pred_copy)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "plot = disp.plot()\n",
    "plot.figure_.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd601cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_idx = 1\n",
    "data = torch.load(performance_file)[fold_idx]\n",
    "\n",
    "cm, f1, auc = data[\"cm\"], data[\"f1\"], data[\"auc\"]\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "disp.plot()\n",
    "print(f\"LOO performance of fold {fold_idx}:\")\n",
    "print(f\"AUC={auc}\")\n",
    "print(f\"F1={f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick viz\n",
    "count_dict = dict()\n",
    "for pep in unique_peptides:\n",
    "    total = len(metadata[metadata[\"peptide\"] == pep])\n",
    "    pos = len(metadata[(metadata[\"peptide\"] == pep) & (metadata[\"binder\"] == 1)])\n",
    "    count_dict[pep] = [total, pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c32bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ddd404",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "peptides = list(count_dict.keys())\n",
    "negatives = [x[0] - x[1] for x in count_dict.values()]\n",
    "positives = [x[1] for x in count_dict.values()]\n",
    "\n",
    "width = 0.4\n",
    "idx = np.arange(len(unique_peptides))\n",
    "\n",
    "ax.bar(idx, negatives, width, zorder=3)\n",
    "ax.bar(idx + width, positives, width, zorder=3)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xticks(idx+width)\n",
    "ax.set_xticklabels(count_dict.keys(), rotation=45)\n",
    "\n",
    "ax.grid(zorder=0, which='both', axis='y')\n",
    "\n",
    "plt.legend([\"Negatives\", \"Positives\"])\n",
    "plt.xlabel(\"Peptide\")\n",
    "plt.ylabel(\"log(Count)\")\n",
    "plt.title(\"Number of TCR-pMHC models for each unique peptide (log-scale)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aaaab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
