{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae57682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f71f810d6d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/home/sebastian/masters/') # add my repo to python path\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import kmbio  # fork of biopython PDB with some changes in how the structure, chain, etc. classes are defined.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import proteinsolver\n",
    "import modules\n",
    "\n",
    "#from Bio import SeqIO\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, BatchSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import *\n",
    "from torch import nn, optim\n",
    "from pathlib import Path\n",
    "\n",
    "from modules.dataset import *\n",
    "from modules.utils import *\n",
    "from modules.models import *\n",
    "from modules.lstm_utils import *\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65af8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"/home/sebastian/masters/data/\")\n",
    "data_root = root / \"neat_data\"\n",
    "metadata_path = data_root / \"metadata.csv\"\n",
    "processed_dir = data_root / \"processed\" / \"tcr_binding\"\n",
    "state_file = root / \"state_files\" / \"e53-s1952148-d93703104.state\"\n",
    "out_dir = root / \"state_files\" / \"tcr_binding\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e604b14",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f49f604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#ID</th>\n",
       "      <th>CDR3a</th>\n",
       "      <th>CDR3b</th>\n",
       "      <th>peptide</th>\n",
       "      <th>partition</th>\n",
       "      <th>binder</th>\n",
       "      <th>v_gene_alpha</th>\n",
       "      <th>j_gene_alpha</th>\n",
       "      <th>v_gene_beta</th>\n",
       "      <th>j_gene_beta</th>\n",
       "      <th>origin</th>\n",
       "      <th>v_alpha_vdjdb_name</th>\n",
       "      <th>j_alpha_vdjdb_name</th>\n",
       "      <th>v_beta_vdjdb_name</th>\n",
       "      <th>j_beta_vdjdb_name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AVSQSNTGKLI</td>\n",
       "      <td>ASSQLMENTEAF</td>\n",
       "      <td>NLVPMVATV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAV12-2</td>\n",
       "      <td>TRAJ37</td>\n",
       "      <td>TRBV4-1</td>\n",
       "      <td>TRBJ1-1</td>\n",
       "      <td>tenX</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>TRAJ37*01</td>\n",
       "      <td>TRBV4-1*01</td>\n",
       "      <td>TRBJ1-1*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AASEVCADYKLS</td>\n",
       "      <td>ASSYSLLRAAPNTEAF</td>\n",
       "      <td>NLVPMVATV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAV29DV5</td>\n",
       "      <td>TRAJ20</td>\n",
       "      <td>TRBV6-3</td>\n",
       "      <td>TRBJ1-1</td>\n",
       "      <td>tenX</td>\n",
       "      <td>TRAV29/DV5*01</td>\n",
       "      <td>TRAJ20*01</td>\n",
       "      <td>TRBV6-3*01</td>\n",
       "      <td>TRBJ1-1*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AGRLGAQKLV</td>\n",
       "      <td>ASSQGGRRNQPQH</td>\n",
       "      <td>NLVPMVATV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAV25</td>\n",
       "      <td>TRAJ54</td>\n",
       "      <td>TRBV4-2</td>\n",
       "      <td>TRBJ1-5</td>\n",
       "      <td>tenX</td>\n",
       "      <td>TRAV25*01</td>\n",
       "      <td>TRAJ54*01</td>\n",
       "      <td>TRBV4-2*01</td>\n",
       "      <td>TRBJ1-5*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AVEPLYGNKLV</td>\n",
       "      <td>ASSSREAEAF</td>\n",
       "      <td>NLVPMVATV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAV22</td>\n",
       "      <td>TRAJ47</td>\n",
       "      <td>TRBV7-9</td>\n",
       "      <td>TRBJ1-1</td>\n",
       "      <td>tenX</td>\n",
       "      <td>TRAV22*01</td>\n",
       "      <td>TRAJ47*01</td>\n",
       "      <td>TRBV7-9*01</td>\n",
       "      <td>TRBJ1-1*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ASGTYKYI</td>\n",
       "      <td>ASSQRAGRVDTQY</td>\n",
       "      <td>NLVPMVATV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAV19</td>\n",
       "      <td>TRAJ40</td>\n",
       "      <td>TRBV27</td>\n",
       "      <td>TRBJ2-3</td>\n",
       "      <td>tenX</td>\n",
       "      <td>TRAV19*01</td>\n",
       "      <td>TRAJ40*01</td>\n",
       "      <td>TRBV27*01</td>\n",
       "      <td>TRBJ2-3*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>12961</td>\n",
       "      <td>AVNSYYNQGGKLI</td>\n",
       "      <td>SVLQGSPYEQY</td>\n",
       "      <td>GILGFVFTL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>TRAJ23*01</td>\n",
       "      <td>TRBV29-1*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>TRAJ23*01</td>\n",
       "      <td>TRBV29-1*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10327</th>\n",
       "      <td>12962</td>\n",
       "      <td>AGNYGGSQGNLI</td>\n",
       "      <td>ASSIYSVNEQF</td>\n",
       "      <td>GILGFVFTL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAV35*01</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-1*01</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRAV35*01</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-1*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>12966</td>\n",
       "      <td>AVGGSQGNLI</td>\n",
       "      <td>ASSVRSSYEQY</td>\n",
       "      <td>GILGFVFTL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAV8-6*02</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRAV8-6*01</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329</th>\n",
       "      <td>12968</td>\n",
       "      <td>AENGGGGADGLT</td>\n",
       "      <td>ASSIRSSYEQY</td>\n",
       "      <td>GILGFVFTL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAV13-2*01</td>\n",
       "      <td>TRAJ45*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRAV13-2*01</td>\n",
       "      <td>TRAJ45*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10330</th>\n",
       "      <td>12971</td>\n",
       "      <td>AVSGSQGNLI</td>\n",
       "      <td>ASSLRSSYEQY</td>\n",
       "      <td>GILGFVFTL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TRAV8-6*02</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRAV8-6*01</td>\n",
       "      <td>TRAJ42*01</td>\n",
       "      <td>TRBV19*01</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>/home/sebastian/masters/data/neat_data/raw/tcr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10331 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         #ID          CDR3a             CDR3b    peptide  partition  binder  \\\n",
       "0          1    AVSQSNTGKLI      ASSQLMENTEAF  NLVPMVATV          1       0   \n",
       "1          2   AASEVCADYKLS  ASSYSLLRAAPNTEAF  NLVPMVATV          1       0   \n",
       "2          3     AGRLGAQKLV     ASSQGGRRNQPQH  NLVPMVATV          1       0   \n",
       "3          4    AVEPLYGNKLV        ASSSREAEAF  NLVPMVATV          1       0   \n",
       "4          5       ASGTYKYI     ASSQRAGRVDTQY  NLVPMVATV          1       0   \n",
       "...      ...            ...               ...        ...        ...     ...   \n",
       "10326  12961  AVNSYYNQGGKLI       SVLQGSPYEQY  GILGFVFTL          1       1   \n",
       "10327  12962   AGNYGGSQGNLI       ASSIYSVNEQF  GILGFVFTL          1       1   \n",
       "10328  12966     AVGGSQGNLI       ASSVRSSYEQY  GILGFVFTL          1       1   \n",
       "10329  12968   AENGGGGADGLT       ASSIRSSYEQY  GILGFVFTL          1       1   \n",
       "10330  12971     AVSGSQGNLI       ASSLRSSYEQY  GILGFVFTL          1       1   \n",
       "\n",
       "      v_gene_alpha j_gene_alpha  v_gene_beta j_gene_beta    origin  \\\n",
       "0         TRAV12-2       TRAJ37      TRBV4-1     TRBJ1-1      tenX   \n",
       "1        TRAV29DV5       TRAJ20      TRBV6-3     TRBJ1-1      tenX   \n",
       "2           TRAV25       TRAJ54      TRBV4-2     TRBJ1-5      tenX   \n",
       "3           TRAV22       TRAJ47      TRBV7-9     TRBJ1-1      tenX   \n",
       "4           TRAV19       TRAJ40       TRBV27     TRBJ2-3      tenX   \n",
       "...            ...          ...          ...         ...       ...   \n",
       "10326  TRAV12-2*01    TRAJ23*01  TRBV29-1*01  TRBJ2-7*01  positive   \n",
       "10327    TRAV35*01    TRAJ42*01    TRBV19*01  TRBJ2-1*01  positive   \n",
       "10328   TRAV8-6*02    TRAJ42*01    TRBV19*01  TRBJ2-7*01  positive   \n",
       "10329  TRAV13-2*01    TRAJ45*01    TRBV19*01  TRBJ2-7*01  positive   \n",
       "10330   TRAV8-6*02    TRAJ42*01    TRBV19*01  TRBJ2-7*01  positive   \n",
       "\n",
       "      v_alpha_vdjdb_name  j_alpha_vdjdb_name  v_beta_vdjdb_name  \\\n",
       "0            TRAV12-2*01           TRAJ37*01         TRBV4-1*01   \n",
       "1          TRAV29/DV5*01           TRAJ20*01         TRBV6-3*01   \n",
       "2              TRAV25*01           TRAJ54*01         TRBV4-2*01   \n",
       "3              TRAV22*01           TRAJ47*01         TRBV7-9*01   \n",
       "4              TRAV19*01           TRAJ40*01          TRBV27*01   \n",
       "...                  ...                 ...                ...   \n",
       "10326        TRAV12-2*01           TRAJ23*01        TRBV29-1*01   \n",
       "10327          TRAV35*01           TRAJ42*01          TRBV19*01   \n",
       "10328         TRAV8-6*01           TRAJ42*01          TRBV19*01   \n",
       "10329        TRAV13-2*01           TRAJ45*01          TRBV19*01   \n",
       "10330         TRAV8-6*01           TRAJ42*01          TRBV19*01   \n",
       "\n",
       "       j_beta_vdjdb_name                                               path  \n",
       "0             TRBJ1-1*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "1             TRBJ1-1*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "2             TRBJ1-5*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "3             TRBJ1-1*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "4             TRBJ2-3*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "...                  ...                                                ...  \n",
       "10326         TRBJ2-7*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "10327         TRBJ2-1*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "10328         TRBJ2-7*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "10329         TRBJ2-7*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "10330         TRBJ2-7*01  /home/sebastian/masters/data/neat_data/raw/tcr...  \n",
       "\n",
       "[10331 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = data_root / \"raw\" / \"tcrpmhc\"\n",
    "\n",
    "paths = list(model_dir.glob(\"*\"))\n",
    "join_key = [int(x.name.split(\"_\")[0]) for x in paths]\n",
    "path_df = pd.DataFrame({'#ID': join_key, 'path': paths})\n",
    "\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "metadata = metadata.join(path_df.set_index(\"#ID\"), on=\"#ID\", how=\"inner\")  # filter to non-missing data\n",
    "metadata = metadata.reset_index(drop=True)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e48700",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_peptides = metadata[\"peptide\"].unique()\n",
    "\n",
    "metadata[\"merged_chains\"] = metadata[\"CDR3a\"] + metadata[\"CDR3b\"]\n",
    "loo_train_partitions = list()\n",
    "loo_valid_partitions = list()\n",
    "for pep in unique_peptides:\n",
    "    valid_df = metadata[metadata[\"peptide\"] == pep]\n",
    "    valid_unique_cdr = valid_df[\"merged_chains\"].unique()\n",
    "    \n",
    "    # get training rows and drop swapped data\n",
    "    train_df = metadata[metadata[\"peptide\"] != pep]\n",
    "    train_df = train_df[~train_df[\"merged_chains\"].str.contains('|'.join(valid_unique_cdr))]\n",
    "\n",
    "    loo_train_partitions.append(list(train_df.index))\n",
    "    loo_valid_partitions.append(list(valid_df.index))\n",
    "\n",
    "# hacky dataset fix\n",
    "# hacky dataset fix\n",
    "# hacky dataset fix\n",
    "filtered_peptides = [\"CLGGLLTMV\", \"ILKEPVHGV\"]\n",
    "filtered_indices = list()\n",
    "filtered_partitions = list()\n",
    "\n",
    "for pep in filtered_peptides:\n",
    "    filtered_indices.extend(list(metadata[metadata[\"peptide\"] == pep].index))\n",
    "    filtered_partitions.extend(np.where(unique_peptides == pep)[0])\n",
    "\n",
    "loo_train_partitions = [part for i, part in enumerate(loo_train_partitions) if i not in filtered_partitions]\n",
    "loo_valid_partitions = [part for i, part in enumerate(loo_valid_partitions) if i not in filtered_partitions]\n",
    "\n",
    "filtered_indices = set(filtered_indices)\n",
    "\n",
    "for i in range(len(loo_train_partitions)):\n",
    "    train_part, valid_part = loo_train_partitions[i], loo_valid_partitions[i]\n",
    "    train_part = [i for i in train_part if i not in filtered_indices]\n",
    "    valid_part = [i for i in valid_part if i not in filtered_indices]\n",
    "    loo_train_partitions[i], loo_valid_partitions[i] = train_part, valid_part\n",
    "    \n",
    "unique_peptides = np.delete(unique_peptides, filtered_partitions)\n",
    "\n",
    "raw_files = np.array(metadata[\"path\"])\n",
    "targets = np.array(metadata[\"binder\"])\n",
    "dataset = ProteinDataset(processed_dir, raw_files, targets, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd9739b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8381, 1217, 9598)\n",
      "(10214, 70, 10284)\n",
      "(10174, 87, 10261)\n",
      "(10017, 201, 10218)\n",
      "(10253, 39, 10292)\n",
      "(10236, 54, 10290)\n",
      "(10182, 89, 10271)\n",
      "(10169, 86, 10255)\n",
      "(9946, 217, 10163)\n",
      "(10262, 34, 10296)\n",
      "(9917, 245, 10162)\n",
      "(7613, 1667, 9280)\n",
      "(10192, 76, 10268)\n",
      "(2011, 6223, 8234)\n",
      "(10306, 8, 10314)\n",
      "(10308, 7, 10315)\n"
     ]
    }
   ],
   "source": [
    "for x in [(len(x), len(y), len(x)+len(y)) for x,y in zip(loo_train_partitions, loo_valid_partitions)]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bada1005",
   "metadata": {},
   "source": [
    "### ProteinSolver model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "003aa8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class MyGNN(nn.Module):\n",
    "    def __init__(self, x_input_size, adj_input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_x = nn.Sequential(\n",
    "            nn.Embedding(x_input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "        self.embed_adj = (\n",
    "            nn.Sequential(\n",
    "                nn.Linear(adj_input_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.LayerNorm(hidden_size),\n",
    "                # nn.ELU(),\n",
    "            )\n",
    "            if adj_input_size\n",
    "            else None\n",
    "        )\n",
    "        self.graph_conv_0 = get_graph_conv_layer(\n",
    "            (2 + bool(adj_input_size)) * hidden_size, 2 * hidden_size, hidden_size\n",
    "        )\n",
    "\n",
    "        N = 3\n",
    "        graph_conv = get_graph_conv_layer(3 * hidden_size, 2 * hidden_size, hidden_size)\n",
    "        self.graph_conv = _get_clones(graph_conv, N)\n",
    "\n",
    "        self.linear_out = nn.Linear(hidden_size, output_size)  # re-assign to (hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = self.forward_without_last_layer(x, edge_index, edge_attr)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.linear_out(x)\n",
    "        return x\n",
    "\n",
    "    def forward_without_last_layer(self, x, edge_index, edge_attr):\n",
    "        x = self.embed_x(x)\n",
    "        # edge_index, _ = add_self_loops(edge_index)  # We should remove self loops in this case!\n",
    "        edge_attr = self.embed_adj(edge_attr) if edge_attr is not None else None\n",
    "\n",
    "        x_out, edge_attr_out = self.graph_conv_0(x, edge_index, edge_attr)\n",
    "        x = x + x_out\n",
    "        edge_attr = (\n",
    "            (edge_attr + edge_attr_out) if edge_attr is not None else edge_attr_out\n",
    "        )\n",
    "\n",
    "        for i in range(3):\n",
    "            x = F.relu(x)\n",
    "            edge_attr = F.relu(edge_attr)\n",
    "            x_out, edge_attr_out = self.graph_conv[i](x, edge_index, edge_attr)\n",
    "            x = x + x_out\n",
    "            edge_attr = edge_attr + edge_attr_out\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "def _get_clones(module, N):\n",
    "    return ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "\n",
    "def gnn_train(\n",
    "    model,\n",
    "    epochs,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    #scheduler,\n",
    "    dataset,\n",
    "    train_idx,\n",
    "    valid_idx,\n",
    "    batch_size,\n",
    "    device,\n",
    "    extra_print=None,\n",
    "):\n",
    "    train_losses = list()\n",
    "    valid_losses = list()\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        train_sampler = BatchSampler(SubsetRandomSampler(train_idx), batch_size=batch_size, drop_last=False)\n",
    "        valid_sampler = BatchSampler(SubsetRandomSampler(valid_idx), batch_size=1, drop_last=False)\n",
    "        \n",
    "        train_loader = torch_geometric.loader.DataLoader(dataset=dataset, batch_sampler=train_sampler)\n",
    "        valid_loader = torch_geometric.loader.DataLoader(dataset=dataset, batch_sampler=valid_sampler)\n",
    "\n",
    "        train_len = len(train_loader)\n",
    "        valid_len = len(valid_loader)\n",
    "        \n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        j = 0\n",
    "        for data in train_loader:    \n",
    "            data.y = data.y.to(device)\n",
    "            y_pred = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(y_pred, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            display_func(j, train_len, e, train_losses, valid_losses, extra_print)\n",
    "            j += 1\n",
    "        \n",
    "        valid_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:    \n",
    "                data.y = data.y.to(device)\n",
    "                y_pred = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze(1)\n",
    "                loss = criterion(y_pred, data.y)\n",
    "                valid_loss += loss.item()\n",
    "        \n",
    "        #scheduler.step()\n",
    "        train_losses.append(train_loss / train_len)\n",
    "        valid_losses.append(valid_loss / valid_len)\n",
    "\n",
    "    return model, train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ae0d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 - n: 25/25 - [========================================================100%]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([1])) must be the same as input size (torch.Size([1, 1]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1293/2282893775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mvalid_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m gnn_train(\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mgnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1293/3259694126.py\u001b[0m in \u001b[0;36mgnn_train\u001b[0;34m(model, epochs, criterion, optimizer, dataset, train_idx, valid_idx, batch_size, device, extra_print)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0mvalid_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    714\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([1])) must be the same as input size (torch.Size([1, 1]))"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# init proteinsolver gnn\n",
    "num_features = 20\n",
    "adj_input_size = 2\n",
    "hidden_size = 128\n",
    "\n",
    "gnn = MyGNN(\n",
    "    x_input_size=num_features + 1, \n",
    "    adj_input_size=adj_input_size, \n",
    "    hidden_size=hidden_size, \n",
    "    output_size=num_features\n",
    ")\n",
    "gnn.load_state_dict(torch.load(state_file, map_location=device))\n",
    "gnn.linear_out = nn.Linear(hidden_size, 1)\n",
    "\n",
    "#gnn.eval()\n",
    "gnn = gnn.to(device)\n",
    "\n",
    "#https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=CN3sRVuaQ88l\n",
    "\n",
    "learning_rate = 1e-2\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(\n",
    "    gnn.parameters(), \n",
    "    lr=learning_rate, \n",
    "    #weight_decay=w_decay,\n",
    ")\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 2\n",
    "train_idx = list(range(50))\n",
    "valid_idx = list(range(50, 60))\n",
    "\n",
    "gnn_train(\n",
    "    gnn,\n",
    "    epochs,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    #scheduler,\n",
    "    dataset,\n",
    "    train_idx,\n",
    "    valid_idx,\n",
    "    batch_size,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eba5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 3\n",
    "#train_idx = list(range(1000))\n",
    "#train_sampler = BatchSampler(SubsetRandomSampler(train_idx), batch_size=batch_size, drop_last=False)\n",
    "#data_loader = iter(torch_geometric.loader.DataLoader(dataset, batch_sampler=train_sampler))\n",
    "#data_loader = iter(torch_geometric.loader.DataLoader(dataset, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c397c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = next(data_loader)\n",
    "#print(data.x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd1a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = gnn(data.x, data.edge_index, data.edge_attr, data.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = y_pred\n",
    "#loss = criterion(y_pred, data.y)\n",
    "#loss.backward()\n",
    "#optimizer.step()\n",
    "#optimizer.zero_grad()\n",
    "#\n",
    "#print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
