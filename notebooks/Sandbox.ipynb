{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ee71536",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/sebastian/masters/') # add my repo to python path\n",
    "import os\n",
    "import torch\n",
    "import torch_geometric\n",
    "import Bio.PDB as PDB\n",
    "import kmbio  # fork of biopython PDB with some changes in how the structure, chain, etc. classes are defined.\n",
    "import numpy as np\n",
    "import proteinsolver\n",
    "import pandas as pd\n",
    "\n",
    "import modules\n",
    "\n",
    "from modules.dataset_utils import *\n",
    "from modules.dataset import *\n",
    "from modules.utils import *\n",
    "from modules.models import *\n",
    "from modules.lstm_utils import *\n",
    "\n",
    "from pathlib import Path\n",
    "# custom stuff\n",
    "#import proteinsolver_utils\n",
    "#import proteinsolver_datasets\n",
    "np.random.seed(0)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b495900",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"/home/sebastian/masters/data/\")\n",
    "data_root = root / \"neat_data\"\n",
    "metadata_path = data_root / \"metadata.csv\"\n",
    "processed_dir = data_root / \"processed\"\n",
    "state_file = root / \"state_files\" / \"e53-s1952148-d93703104.state\"\n",
    "out_dir = root / \"state_files\" / \"tcr_binding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc61d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give path to ida data dir and metadata file (here, metadata row = idx of file)\n",
    "# glob and load file sequentially\n",
    "# split on _ to get index/target and partition\n",
    "# send file path to partition\n",
    "#\n",
    "# when loading data during training, slice out each time variable from the data\n",
    "# convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1ee412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOO validation\n",
    "model_energies_dir = data_root / \"test\"\n",
    "\n",
    "paths = list(model_energies_dir.glob(\"*\"))\n",
    "join_key = [int(x.name.split(\"_\")[0]) for x in paths]\n",
    "path_df = pd.DataFrame({'#ID': join_key, 'path': paths})\n",
    "\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "metadata = metadata.join(path_df.set_index(\"#ID\"), on=\"#ID\", how=\"inner\")  # filter to non-missing data\n",
    "metadata = metadata.sort_values(by=\"#ID\")\n",
    "metadata = metadata.reset_index(drop=True)\n",
    "\n",
    "LSTMEnergyDataset(\n",
    "    paths=metadata[\"paths\"]\n",
    "    targets=metadata[binder]\n",
    ")\n",
    "\n",
    "\n",
    "#loo_train_partitions, loo_test_partitions, loo_valid_partitions, unique_peptides = generate_3_loo_partitions(metadata, valid_pep=\"KTWGQYWQV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "838ab26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "i = 1\n",
    "test_idx = partitions[i]\n",
    "partitions = [[\"A\"], [\"B\"], [\"C\"], [\"D\"], [\"E\"]]\n",
    "outer_train_folds = [partitions[j] for j in range(n_splits) if j != i]\n",
    "inner_train_partitions, inner_valid_partitions = join_partitions(outer_train_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7fa1d068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test ['B']\n",
      "train [['A'], ['C'], ['D'], ['E']]\n",
      "inner train [['C', 'D', 'E'], ['A', 'D', 'E'], ['A', 'C', 'E'], ['A', 'C', 'D']]\n",
      "inner valid [['A'], ['C'], ['D'], ['E']]\n"
     ]
    }
   ],
   "source": [
    "print(\"test\", test_idx)\n",
    "print(\"train\", outer_train_folds)\n",
    "print(\"inner train\", inner_train_partitions)\n",
    "print(\"inner valid\", inner_valid_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold CV\n",
    "\n",
    "metadata_path = data_root / \"metadata.csv\"\n",
    "\n",
    "partitions = [list() for _ in range(5)]\n",
    "targets = list()\n",
    "\n",
    "paths = list(model_dir.glob(\"*\"))\n",
    "for path in paths:\n",
    "    split = str(path).split(\"_\")\n",
    "    \n",
    "    bind_str = split[-2]\n",
    "    if bind_str == \"pos\":\n",
    "        bind = 1\n",
    "    else:\n",
    "        bind = 0\n",
    "    targets.append(bind)\n",
    "    \n",
    "    part = int(split[-3][0]) - 1\n",
    "    partitions[part].append(path)\n",
    "\n",
    "LSTMEnergyDataset(\n",
    "    paths=paths\n",
    "    targets=targets\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEnergyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        paths, \n",
    "        targets, \n",
    "        transform=None, \n",
    "        target_transform=None\n",
    "    ):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.annotations = torch.Tensor(targts)\n",
    "        self.paths = paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.load(self.paths[idx])\n",
    "        time_idx = [92, 116, 140]  # time variables to be removed\n",
    "        for idx in time_idx:\n",
    "            x[:,idx] = 0.0\n",
    "        x = torch.from_numpy(x)\n",
    "        y = self.annotations[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f88e8531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"/home/sebastian/masters/data/neat_data/9978_2p_neg_swap.npy\".split(\"_\")\n",
    "int(t[-3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "551805f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([406, 142])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.load(\"/home/sebastian/masters/data/neat_data/9978_2p_neg_swap.npy\")\n",
    "torch.from_numpy(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c956203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([414, 132])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(processed_dir / \"proteinsolver_embeddings_pos/data_1.pt\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6d2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LSTMDataset(\n",
    "    data_dir=processed_dir / \"proteinsolver_embeddings\", \n",
    "    annotations_path=processed_dir / \"proteinsolver_embeddings\" / \"targets.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "047bb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = list()\n",
    "for i in range(len(dataset)):\n",
    "    lens.append(len(dataset[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36952e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   5.,   4.,  17.,  24.,  76.,  86., 100., 100., 236.,\n",
       "        262., 360., 577., 606., 931., 957., 920., 956., 902., 740., 734.,\n",
       "        554., 457., 311., 197., 120.,  66.,  22.,  10.]),\n",
       " array([390., 391., 392., 393., 394., 395., 396., 397., 398., 399., 400.,\n",
       "        401., 402., 403., 404., 405., 406., 407., 408., 409., 410., 411.,\n",
       "        412., 413., 414., 415., 416., 417., 418., 419., 420.]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQJ0lEQVR4nO3df6zdd13H8eeLFsYvF7rsbqn9YUtSkY0EkZs5JSJxShtK6Ixp0kS0ypIGUxV/JNDqH0RNkwLG4K9hGgRLQJoGMatbUJrqRBPYaNmQdaVZpbO7rK4Fo4Ixg5a3f5zv5Oz23u6ec27vPfd+no/k5ny/n/v5nu/n08/2Op/7+Z7zPakqJElteN5iN0CStHAMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhjxn6Cf5UJILSR7pK7shydEkj3WPq/p+tzfJmSSnk2zuK39tki91v/ujJJn/7kiSrmYuM/2/ALZMK9sDHKuqTcCxbp8ktwA7gFu7Y+5OsqI75gPALmBT9zP9OSVJ19jK56pQVZ9JsmFa8TbgDd32QeB+4F1d+aGqeho4m+QMcFuSx4Hrq+qzAEk+AtwJfOq5zn/jjTfWhg3TTy9JupoTJ058raomppc/Z+jP4uaqOg9QVeeT3NSVrwE+11dvqiv7drc9vXxGSXbR+6uA9evXc/z48SGbKUltSvJvM5XP94Xcmdbp6yrlM6qqA1U1WVWTExNXvFBJkoY0bOg/lWQ1QPd4oSufAtb11VsLPNmVr52hXJK0gIYN/SPAzm57J3BPX/mOJNcl2Ujvgu2D3VLQN5Lc3r1r5+f7jpEkLZDnXNNP8nF6F21vTDIFvBvYDxxOchdwDtgOUFUnkxwGHgUuAbur6nL3VL9E751AL6J3Afc5L+JKkuZXxv3WypOTk+WFXEkaTJITVTU5vdxP5EpSQwx9SWqIoS9JDTH0Jakhw34iV9Icbdhz35zqPb5/66I+p9rgTF+SGmLoS1JDDH1JaoihL0kN8UKuNKS5XkyVxokzfUlqiKEvSQ1xeUcaEy4XaSE405ekhhj6ktQQQ1+SGuKavrSMeY8eTedMX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhoyUugn+fUkJ5M8kuTjSV6Y5IYkR5M81j2u6qu/N8mZJKeTbB69+ZKkQQwd+knWAL8KTFbVq4AVwA5gD3CsqjYBx7p9ktzS/f5WYAtwd5IVozVfkjSIUZd3VgIvSrISeDHwJLANONj9/iBwZ7e9DThUVU9X1VngDHDbiOeXJA1g6NCvqq8Cvw+cA84D/1VVnwZurqrzXZ3zwE3dIWuAJ/qeYqorkyQtkFGWd1bRm71vBL4XeEmSt17tkBnKapbn3pXkeJLjFy9eHLaJkqRpRlne+UngbFVdrKpvA58EfhR4KslqgO7xQld/CljXd/xaestBV6iqA1U1WVWTExMTIzRRktRvlNA/B9ye5MVJAtwBnAKOADu7OjuBe7rtI8COJNcl2QhsAh4c4fySpAGtHPbAqnogySeALwCXgIeAA8BLgcNJ7qL3wrC9q38yyWHg0a7+7qq6PGL7JUkDGDr0Aarq3cC7pxU/TW/WP1P9fcC+Uc4pSRqen8iVpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNWSkD2dJWh427LlvTvUe37/1GrdE15qhL2nOfHFY+lzekaSGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGjBT6SV6W5BNJvpzkVJIfSXJDkqNJHuseV/XV35vkTJLTSTaP3nxJ0iBGnen/IfC3VfUDwKuBU8Ae4FhVbQKOdfskuQXYAdwKbAHuTrJixPNLkgawctgDk1wPvB74BYCq+hbwrSTbgDd01Q4C9wPvArYBh6rqaeBskjPAbcBnh22DdC1s2HPfYjdBumZGmem/HLgIfDjJQ0k+mOQlwM1VdR6ge7ypq78GeKLv+Kmu7ApJdiU5nuT4xYsXR2iiJKnfKKG/Evgh4ANV9Rrgf+iWcmaRGcpqpopVdaCqJqtqcmJiYoQmSpL6jRL6U8BUVT3Q7X+C3ovAU0lWA3SPF/rqr+s7fi3w5AjnlyQNaOjQr6p/B55I8oqu6A7gUeAIsLMr2wnc020fAXYkuS7JRmAT8OCw55ckDW7oC7mdXwE+luQFwFeAX6T3QnI4yV3AOWA7QFWdTHKY3gvDJWB3VV0e8fySpAGMFPpV9TAwOcOv7pil/j5g3yjnlIblu3IkP5ErSU0x9CWpIYa+JDXE0Jekhoz67h1JusJcL5o/vn/rNW6JpnOmL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0JekhvjF6JIWjV+gvvCc6UtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaMnLoJ1mR5KEk93b7NyQ5muSx7nFVX929Sc4kOZ1k86jnliQNZj5m+u8ATvXt7wGOVdUm4Fi3T5JbgB3ArcAW4O4kK+bh/JKkORop9JOsBbYCH+wr3gYc7LYPAnf2lR+qqqer6ixwBrhtlPNLkgYz6kz//cA7ge/0ld1cVecBusebuvI1wBN99aa6sisk2ZXkeJLjFy9eHLGJkqRnDB36Sd4MXKiqE3M9ZIaymqliVR2oqsmqmpyYmBi2iZKkaUa5y+brgLckeRPwQuD6JB8FnkqyuqrOJ1kNXOjqTwHr+o5fCzw5wvklSQMaeqZfVXuram1VbaB3gfbvq+qtwBFgZ1dtJ3BPt30E2JHkuiQbgU3Ag0O3XJI0sGtxP/39wOEkdwHngO0AVXUyyWHgUeASsLuqLl+D80uSZjEvoV9V9wP3d9tfB+6Ypd4+YN98nFOSNDg/kStJDTH0Jakhhr4kNcQvRteSN9cv15bkTF+SmmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQ7wNg6SxN8itNh7fv/UatmTpc6YvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kN8RO5Glt+4bk0/5zpS1JDDH1JaoihL0kNMfQlqSGGviQ1xHfvaEH5jhxpcTnTl6SGGPqS1BBDX5IaMnToJ1mX5B+SnEpyMsk7uvIbkhxN8lj3uKrvmL1JziQ5nWTzfHRAkjR3o8z0LwG/WVWvBG4Hdie5BdgDHKuqTcCxbp/udzuAW4EtwN1JVozSeEnSYIYO/ao6X1Vf6La/AZwC1gDbgINdtYPAnd32NuBQVT1dVWeBM8Btw55fkjS4eVnTT7IBeA3wAHBzVZ2H3gsDcFNXbQ3wRN9hU12ZJGmBjPw+/SQvBf4K+LWq+u8ks1adoaxmec5dwC6A9evXj9pESQ2Z62dBHt+/9Rq3ZDyNNNNP8nx6gf+xqvpkV/xUktXd71cDF7ryKWBd3+FrgSdnet6qOlBVk1U1OTExMUoTJUl9Rnn3ToA/B05V1R/0/eoIsLPb3gnc01e+I8l1STYCm4AHhz2/JGlwoyzvvA74OeBLSR7uyn4L2A8cTnIXcA7YDlBVJ5McBh6l986f3VV1eYTzS5IGNHToV9U/M/M6PcAdsxyzD9g37DklSaPxE7mS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JasjIX6IiSUtRq1+24kxfkhpi6EtSQwx9SWqIa/q6qrmue0paGpzpS1JDDH1JaojLO41y2UZqkzN9SWqIM/1lxhm8pKtxpi9JDTH0JakhLu9I0lUst3v0ONOXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcQPZy0R3lNHGm9L5UNchv4iMsglLbQFX95JsiXJ6SRnkuxZ6PNLUssWdKafZAXwp8BPAVPA55McqapHF7IdkrRYFnsZaKGXd24DzlTVVwCSHAK2AUsi9F2OkbTULXTorwGe6NufAn54eqUku4Bd3e43k5we8nw3Al8b8thxs1z6slz6AfZlXC2LvuQ9I/fj+2YqXOjQzwxldUVB1QHgwMgnS45X1eSozzMOlktflks/wL6Mq+XSl2vVj4W+kDsFrOvbXws8ucBtkKRmLXTofx7YlGRjkhcAO4AjC9wGSWrWgi7vVNWlJL8M/B2wAvhQVZ28hqcceYlojCyXviyXfoB9GVfLpS/XpB+pumJJXZK0THnvHUlqiKEvSQ1ZsqGf5IVJHkzyxSQnk/xOV/7qJJ9N8qUkf5Pk+r5j9na3fzidZPPitf7ZBu1Lkg1J/jfJw93Pny1uD54tyYokDyW5t9u/IcnRJI91j6v66o7lmDxjrn0Z9zGBGfuyvfvv7TtJJqfVHdtxmWs/luiYvC/Jl5P8S5K/TvKyvrrzMyZVtSR/6L3n/6Xd9vOBB4Db6b1D6Me78rcBv9dt3wJ8EbgO2Aj8K7BisfsxZF82AI8sdruv0p/fAP4SuLfbfy+wp9veA7xn3MdkiL6M9ZjM0pdXAq8A7gcm++qN9bgM0I+lOCZvBFZ22++5Fv+vLNmZfvV8s9t9fvdT9Ab/M135UeBnuu1twKGqerqqzgJn6N0WYtEN0ZexlWQtsBX4YF/xNuBgt30QuLOvfCzHBAbuy1ibqS9VdaqqZvq0+9iOy4D9GGuz9OXTVXWp2/0cvc8ywTyOyZINffj/P40eBi4AR6vqAeAR4C1dle1898NgM90CYs1CtfW5DNgXgI3dn4X/mOTHFri5V/N+4J3Ad/rKbq6q8wDd401d+ViPCYP1BcZ3TGDmvsxmnMdlkH7A0h6TtwGf6rbnbUyWdOhX1eWq+kF6r4a3JXkVvX+o3UlOAN8DfKurPqdbQCyWAftyHlhfVa+h+/Ow/9rFYknyZuBCVZ2Y6yEzlI3FmAzRl7EcE1g+49LSmCT5beAS8LFnimaoNtSYLOnQf0ZV/Se99bwtVfXlqnpjVb0W+Di9tS9YIreAmEtfuj/xvt5tn+jKv3+RmtzvdcBbkjwOHAJ+IslHgaeSrAboHi909cd5TAbqyxiPCczel9mM67gM1I+lOiZJdgJvBn62ugV95nNMFvtCxggXQCaAl3XbLwL+qfuHuqkrex7wEeBt3f6tPPtCyFcYk4tTQ/Rl4pm2Ay8HvgrcsNj9mNanN/Ddi1Pv49kXP9877mMyRF/Gfkym96Wv7H6efQF07Mdljv1YcmMCbKF3q/mJaXXmbUyW8tclrgYOpvfFLM8DDlfVvUnekWR3V+eTwIcBqupkksP0/kEvAbur6vJiNHwGA/UFeD3wu0kuAZeBt1fVfyx4q+duP3A4yV3AOXrXJ8Z9TGYzY19YemNCkp8G/pheON6X5OGq2rzUxmW2frAExwT4E3rBfjQJwOeq6u3zOSbehkGSGrIs1vQlSXNj6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SG/B/XsvGjKwL1lAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = np.array(lens)\n",
    "plt.hist(lens, bins=len(np.unique(lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a114e61b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 801 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_779/1471245054.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlen_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mflattened\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_779/4282447565.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 801 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "len_x = np.where(lens == 392)\n",
    "flattened = list()\n",
    "targets = list()\n",
    "for i in len_x[0]:\n",
    "    x, y = dataset[i]\n",
    "    x = x.flatten()\n",
    "    flattened.append(x.numpy())\n",
    "    targets.append(y.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "782dc4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDatasetInMemory(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data_dir, \n",
    "        annotations_path, \n",
    "        transform=None, \n",
    "        target_transform=None\n",
    "    ):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.annotations = torch.Tensor(torch.load(annotations_path))\n",
    "        self.data = np.array(\n",
    "            [torch.load(f\"{self.data_dir}/data_{idx}.pt\") for idx in range(len(self.annotations))],\n",
    "            dtype=object\n",
    "        )\n",
    "    \n",
    "    def add_data(self, new_x, new_y):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.annotations[idx]\n",
    "        return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1ad1e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_779/4282447565.py:13: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  self.data = np.array(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "\n",
    "dataset_1 = LSTMDataset(\n",
    "    data_dir=processed_dir / \"test_data\", \n",
    "    annotations_path=processed_dir / \"test_data\" / \"targets.pt\"\n",
    ")\n",
    "\n",
    "dataset_2 = LSTMDatasetInMemory(\n",
    "    data_dir=processed_dir / \"test_data\", \n",
    "    annotations_path=processed_dir / \"test_data\" / \"targets.pt\"\n",
    ")\n",
    "\n",
    "dataset = dataset_2\n",
    "\n",
    "lengths = np.array([len(dataset[i][0]) for i in range(len(dataset))])\n",
    "\n",
    "n_thresh = 0 #50  # TODO: set some number\n",
    "for length in np.unique(lengths):\n",
    "    length_idx = np.where(lengths == length)[0]\n",
    "    if len(length_idx) > n_thresh:  # replace with try/except. Catches both no positive and too few data error.\n",
    "        x_sub, y_sub = dataset[length_idx]\n",
    "        x_sub = torch.stack([x for x in x_sub])\n",
    "        \n",
    "        # split embedding and pos encoding\n",
    "        emb = x_sub[:,:,:-4]\n",
    "        pos = x_sub[:,:,-4:]\n",
    "        \n",
    "        emb = emb.flatten(1)  # reshape to (n_sample, (emb_dim x len))\n",
    "        \n",
    "        sm = BorderlineSMOTE(sampling_strategy=\"minority\", random_state=0)\n",
    "        x_os, y_os = sm.fit_resample(emb, y_sub.squeeze(1))\n",
    "        x_os = x_os[len(emb):]  # slice to only get syntheic data\n",
    "        y_os = y_os[len(emb):]\n",
    "\n",
    "        new_pos = #make a way to get representative positional encoding from x_sub\n",
    "        x_os = x_os.unflatten(0, torch.Size([length, 128]))  # reshape back to (n_sample, emb_dim, len)\n",
    "        x_os = torch.cat((x_os, new_pos), dim=2)  # add positional encoding\n",
    "\n",
    "# load dataset\n",
    "# get training partition\n",
    "# stratify training partition on length\n",
    "# for each length:\n",
    "    #try:\n",
    "        #join into one tensor\n",
    "        #split off positional encoding\n",
    "        #get positional encoding sequence that is representative of positives\n",
    "        #flatten tensor\n",
    "        #oversample with borderlinesmote\n",
    "        #unflatten tensor\n",
    "        #re-attach positional encodings to true positives\n",
    "        #attach generated positional encoding to synthetic positives\n",
    "    #except low count length or no positive:\n",
    "        #skip oversampling\n",
    "# take oversamplings for each length and join into new dataset\n",
    "# give training data to training func as an iterabledataset instead of map-style\n",
    "\n",
    "# we have to do it in memory since we have to oversample on training partition data only.\n",
    "# maybe its better to do interpolation per peptide?? according to paolos message perhaps\n",
    "\n",
    "\n",
    "#sm = BorderlineSMOTE(sampling_strategy=\"minority\", random_state=0)\n",
    "#x_os, y_os = sm.fit_resample(flattened, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3fd08625",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sub, y_sub = dataset[length_idx]\n",
    "y_sub = torch.stack((y_sub, y_sub, y_sub))\n",
    "y_sub[1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4e726d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = emb[:,:,-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a655978f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2346,  4.3500,  0.7100, -0.3586],\n",
       "         [ 2.6212,  1.3006, -0.1013,  1.9053],\n",
       "         [-2.5463,  2.8244,  1.1419, -1.2915],\n",
       "         ...,\n",
       "         [-2.0430,  0.8236,  1.2853, -2.7416],\n",
       "         [-1.4404,  3.8062,  1.3832,  1.1276],\n",
       "         [-1.4594,  1.0662,  1.4364, -2.3321]],\n",
       "\n",
       "        [[ 0.2346,  4.3500,  0.7100, -0.3586],\n",
       "         [ 2.6212,  1.3006, -0.1013,  1.9053],\n",
       "         [-2.5463,  2.8244,  1.1419, -1.2915],\n",
       "         ...,\n",
       "         [-2.0430,  0.8236,  1.2853, -2.7416],\n",
       "         [-1.4404,  3.8062,  1.3832,  1.1276],\n",
       "         [-1.4594,  1.0662,  1.4364, -2.3321]],\n",
       "\n",
       "        [[ 0.2346,  4.3500,  0.7100, -0.3586],\n",
       "         [ 2.6212,  1.3006, -0.1013,  1.9053],\n",
       "         [-2.5463,  2.8244,  1.1419, -1.2915],\n",
       "         ...,\n",
       "         [-2.0430,  0.8236,  1.2853, -2.7416],\n",
       "         [-1.4404,  3.8062,  1.3832,  1.1276],\n",
       "         [-1.4594,  1.0662,  1.4364, -2.3321]]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "466d51c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 414, 4, 2])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((emb, pos), dim=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "08fd10fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 414, 4])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ba2c8d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 414, 4])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "88661042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2346,  4.3500,  0.7100, -0.3586],\n",
       "         [ 2.6212,  1.3006, -0.1013,  1.9053],\n",
       "         [-2.5463,  2.8244,  1.1419, -1.2915],\n",
       "         ...,\n",
       "         [-2.0430,  0.8236,  1.2853, -2.7416],\n",
       "         [-1.4404,  3.8062,  1.3832,  1.1276],\n",
       "         [-1.4594,  1.0662,  1.4364, -2.3321]],\n",
       "\n",
       "        [[ 0.2346,  4.3500,  0.7100, -0.3586],\n",
       "         [ 2.6212,  1.3006, -0.1013,  1.9053],\n",
       "         [-2.5463,  2.8244,  1.1419, -1.2915],\n",
       "         ...,\n",
       "         [-2.0430,  0.8236,  1.2853, -2.7416],\n",
       "         [-1.4404,  3.8062,  1.3832,  1.1276],\n",
       "         [-1.4594,  1.0662,  1.4364, -2.3321]],\n",
       "\n",
       "        [[ 0.2346,  4.3500,  0.7100, -0.3586],\n",
       "         [ 2.6212,  1.3006, -0.1013,  1.9053],\n",
       "         [-2.5463,  2.8244,  1.1419, -1.2915],\n",
       "         ...,\n",
       "         [-2.0430,  0.8236,  1.2853, -2.7416],\n",
       "         [-1.4404,  3.8062,  1.3832,  1.1276],\n",
       "         [-1.4594,  1.0662,  1.4364, -2.3321]]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d8c78657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2346,  4.3500,  0.7100,  ...,  4.3500,  0.7100, -0.3586],\n",
       "         [ 2.6212,  1.3006, -0.1013,  ...,  1.3006, -0.1013,  1.9053],\n",
       "         [-2.5463,  2.8244,  1.1419,  ...,  2.8244,  1.1419, -1.2915],\n",
       "         ...,\n",
       "         [-2.0430,  0.8236,  1.2853,  ...,  0.8236,  1.2853, -2.7416],\n",
       "         [-1.4404,  3.8062,  1.3832,  ...,  3.8062,  1.3832,  1.1276],\n",
       "         [-1.4594,  1.0662,  1.4364,  ...,  1.0662,  1.4364, -2.3321]],\n",
       "\n",
       "        [[ 0.2346,  4.3500,  0.7100,  ...,  4.3500,  0.7100, -0.3586],\n",
       "         [ 2.6212,  1.3006, -0.1013,  ...,  1.3006, -0.1013,  1.9053],\n",
       "         [-2.5463,  2.8244,  1.1419,  ...,  2.8244,  1.1419, -1.2915],\n",
       "         ...,\n",
       "         [-2.0430,  0.8236,  1.2853,  ...,  0.8236,  1.2853, -2.7416],\n",
       "         [-1.4404,  3.8062,  1.3832,  ...,  3.8062,  1.3832,  1.1276],\n",
       "         [-1.4594,  1.0662,  1.4364,  ...,  1.0662,  1.4364, -2.3321]],\n",
       "\n",
       "        [[ 0.2346,  4.3500,  0.7100,  ...,  4.3500,  0.7100, -0.3586],\n",
       "         [ 2.6212,  1.3006, -0.1013,  ...,  1.3006, -0.1013,  1.9053],\n",
       "         [-2.5463,  2.8244,  1.1419,  ...,  2.8244,  1.1419, -1.2915],\n",
       "         ...,\n",
       "         [-2.0430,  0.8236,  1.2853,  ...,  0.8236,  1.2853, -2.7416],\n",
       "         [-1.4404,  3.8062,  1.3832,  ...,  3.8062,  1.3832,  1.1276],\n",
       "         [-1.4594,  1.0662,  1.4364,  ...,  1.0662,  1.4364, -2.3321]]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b4a405ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_779/1377238495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBorderlineSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minority\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_os\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ps/lib/python3.8/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         y_ = (\n",
      "\u001b[0;32m~/anaconda3/envs/ps/lib/python3.8/site-packages/imblearn/over_sampling/_smote/filter.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             danger_index = self._in_danger_noise(\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"danger\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/ps/lib/python3.8/site-packages/imblearn/over_sampling/_smote/base.py\u001b[0m in \u001b[0;36m_in_danger_noise\u001b[0;34m(self, nn_estimator, samples, target_class, y, kind)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0marray\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0mrefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdanger\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mnn_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mn_maj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ps/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mn_samples_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_fit_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    681\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 11"
     ]
    }
   ],
   "source": [
    "sm = BorderlineSMOTE(sampling_strategy=\"minority\", random_state=0)\n",
    "x_os, y_os = sm.fit_resample(emb.flatten(1), y_sub.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "625c202d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b0f9dea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "165baec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sub = torch.stack((x_sub[0], x_sub[0] ,x_sub[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c79ba666",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = x_sub[:,:,:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e5d0be72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 52992])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.flatten(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "83b63a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4573, -0.2002,  1.6379,  ...,  0.3475,  0.7875,  1.2294],\n",
       "        [-5.4712,  0.9058,  0.8596,  ...,  3.1876, -1.0497,  1.7057],\n",
       "        [-3.2194, -0.0836, -0.0969,  ...,  0.1556, -0.1512, -0.1089],\n",
       "        ...,\n",
       "        [-5.6118,  0.1372, -0.2350,  ..., -4.4966,  1.4147, -1.5574],\n",
       "        [-5.9163,  0.8383,  1.1998,  ...,  3.0196, -0.5474,  1.6051],\n",
       "        [ 0.1068, -0.1263, -0.4633,  ...,  1.2110,  1.3926, -2.2330]])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(x_os[-2]).unflatten(0, torch.Size([396, 128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from_dir = \"/home/sebastian/masters/data/210916_TCRpMHCmodels/models/\"\n",
    "#to_dir = \"/home/sebastian/masters/data/neat_data/tcrpmhc/\"\n",
    "#model_suffix = \"model_TCR-pMHC.pdb\"\n",
    "#for subdir in os.listdir(from_dir):\n",
    "#    subdir_id = subdir.split(\"_\")[0]\n",
    "#    new_name = f\"tcrpmhc_{subdir_id}.pdb\"\n",
    "#    os.system(f\"mv {from_dir}/{subdir}/{model_suffix} {to_dir}/{new_name}\")\n",
    "#    \n",
    "#from_dir = \"/home/sebastian/masters/data/embedding_verification/raw_filtered_models\"\n",
    "#to_dir = \"/home/sebastian/masters/data/neat_data/pmhc/\"\n",
    "#model_suffix = \"model_pMHC.pdb\"\n",
    "#for subdir in os.listdir(from_dir):\n",
    "#    subdir_id = subdir.split(\"_\")[0]\n",
    "#    new_name = f\"pmhc_{subdir_id}.pdb\"\n",
    "#    os.system(f\"mv {from_dir}/{subdir}/{model_suffix} {to_dir}/{new_name}\")\n",
    "#    \n",
    "#from_dir = \"/home/sebastian/masters/data/embedding_verification/raw_filtered_models\"\n",
    "#to_dir = \"/home/sebastian/masters/data/neat_data/p/\"\n",
    "#model_suffix = \"model_p.pdb\"\n",
    "#for subdir in os.listdir(from_dir):\n",
    "#    subdir_id = subdir.split(\"_\")[0]\n",
    "#    new_name = f\"p_{subdir_id}.pdb\"\n",
    "#    os.system(f\"mv {from_dir}/{subdir}/{model_suffix} {to_dir}/{new_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_ID = \"191f05de\"\n",
    "BEST_STATE_FILES = {\n",
    "    #\n",
    "    \"191f05de\": \"/home/sebastian/proteinsolver/data/e53-s1952148-d93703104.state\"\n",
    "}\n",
    "state_file = BEST_STATE_FILES[UNIQUE_ID]\n",
    "\n",
    "\n",
    "#test_file = \"/home/sebastian/proteinsolver/notebooks/protein_demo/inputs/1n5uA03.pdb\"\n",
    "#test_id = \"1n5uA03.pdb\"\n",
    "\n",
    "test_file = \"/home/sebastian/masters/data/test/3hfm.pdb\"\n",
    "test_id = \"3hfm\"\n",
    "\n",
    "def load_model_paths(data_dir, model=\"model_TCR-pMHC.pdb\"):\n",
    "    model_list = list()\n",
    "    for subdir in os.listdir(data_dir):\n",
    "        path = f\"{data_dir}/{subdir}/{model}\"\n",
    "        model_list.append(path)\n",
    "    return np.array(model_list)\n",
    "\n",
    "infiles = load_model_paths(\"/home/sebastian/masters/data/210916_TCRpMHCmodels/models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb016cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_all = kmbio.PDB.load(infiles[0])\n",
    "structure_all = merge_chains(structure_all)\n",
    "structure = kmbio.PDB.Structure(test_id, structure_all[0].extract('A'))\n",
    "\n",
    "pdata = proteinsolver.utils.extract_seq_and_adj(structure, 'A', remove_hetatms=True)\n",
    "data = proteinsolver.datasets.row_to_data(pdata)\n",
    "data = proteinsolver.datasets.transform_edge_attr(data)\n",
    "data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04fe7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20d267c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-52a5e47581cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: softmax() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "F.softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader = iter(torch_geometric.data.DataLoader(d_train, batch_size=batch_size))\n",
    "#valid_loader = iter(torch_geometric.data.DataLoader(d_valid, batch_size=batch_size))\n",
    "#d = next(train_loader)\n",
    "#x = torch.ones_like(d.x)*d.x.max().item()\n",
    "#out = gnn(x, d.edge_index, d.edge_attr)\n",
    "#\n",
    "#net.eval()\n",
    "#with torch.no_grad():\n",
    "#    y = net(out.T.unsqueeze(0))\n",
    "#    y = F.softmax(y, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31befdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_to_fnn(data, hidden_size, gnn_instance):\n",
    "        data = data.to(device)\n",
    "        y = data.y.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = gnn_instance(data.x, data.edge_index, data.edge_attr)\n",
    "        \n",
    "        batches = torch.unique(data.batch)\n",
    "        sliced_outs = list()\n",
    "        pool = nn.AdaptiveAvgPool1d(output_size=hidden_size)\n",
    "        for batch_idx in batches:\n",
    "            batch_slice = torch.nonzero(data.batch == batch_idx)\n",
    "            chain_map = data.chain_map[batch_idx]\n",
    "            out_sliced = out[batch_slice]\n",
    "            out_sliced = out_sliced[chain_map == \"P\"]  # get peptide only\n",
    "            out_sliced = pool(out_sliced.T)\n",
    "            sliced_outs.append(out_sliced)\n",
    "        batched_out = torch.cat(sliced_outs, dim=1)\n",
    "        return out, y\n",
    "    \n",
    "def gnn_to_lstm_batch(data, gnn_instance, device, num_classes):\n",
    "    \"\"\"function for bridging gnn output to lstm\"\"\"\n",
    "    data = data.to(device)\n",
    "    y = data.y\n",
    "    with torch.no_grad():\n",
    "        out = gnn_instance(data.x, data.edge_index, data.edge_attr)\n",
    "    \n",
    "    batches = torch.unique(data.batch)\n",
    "    sliced_embeddings = list()\n",
    "    encoded_y = list()\n",
    "    for batch_idx in batches:\n",
    "        # split sub graphs into batches\n",
    "        batch_slice = torch.nonzero(data.batch == batch_idx)\n",
    "        chain_map = data.chain_map[batch_idx]\n",
    "        one_batch_peptide_emb = out[batch_slice][chain_map == \"P\"]  # get peptide only\n",
    "        sliced_embeddings.append(one_batch_peptide_emb.squeeze(1))\n",
    "        \n",
    "        # one hot encode targets\n",
    "        sliced_y = int(y[batch_idx].item())\n",
    "        one_hot_y = np.zeros(num_classes)\n",
    "        one_hot_y[sliced_y] = 1\n",
    "        encoded_y.append(one_hot_y)\n",
    "        \n",
    "    sliced_embeddings.sort(key=lambda x: len(x))\n",
    "    encoded_y = torch.Tensor(encoded_y)\n",
    "    \n",
    "    return sliced_embeddings, encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbda8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFNN(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(hidden_size * num_features, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)  # output dim should be 3 long\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.T.flatten()\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init proteinsolver gnn\n",
    "num_features = 20\n",
    "adj_input_size = 2\n",
    "hidden_size = 128\n",
    "#frac_present = 0.5\n",
    "#frac_present_valid = frac_present\n",
    "#info_size= 1024\n",
    "\n",
    "gnn = Net(\n",
    "    x_input_size=num_features + 1, \n",
    "    adj_input_size=adj_input_size, \n",
    "    hidden_size=hidden_size, \n",
    "    output_size=num_features\n",
    ")\n",
    "gnn.load_state_dict(torch.load(state_file, map_location=device))\n",
    "gnn.eval()\n",
    "gnn = gnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b171b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import KFold\n",
    "#from sklearn.metrics import *\n",
    "#from torch import nn, optim\n",
    "#import torch.nn.functional as F\n",
    "#\n",
    "#\n",
    "#root = Path(\"/home/sebastian/masters/data/\")\n",
    "#data_root = root / \"neat_data\"\n",
    "#metadata_path = data_root / \"embedding_dataset.csv\"\n",
    "#processed_dir = data_root / \"processed\" / \"embedding_verification\"\n",
    "#state_file = root / \"state_files\" / \"e53-s1952148-d93703104.state\"\n",
    "#out_dir = root / \"state_files\" / \"embedding_verification\" \n",
    "#\n",
    "#device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#\n",
    "## load dataset\n",
    "#raw_files = list()\n",
    "#targets = list()\n",
    "#with open(metadata_path, \"r\") as infile:\n",
    "#    for line in infile:\n",
    "#        line = line.strip().split(\",\")\n",
    "#        raw_files.append(line[0])\n",
    "#        targets.append(int(line[1]))\n",
    "#\n",
    "#raw_files = np.array(raw_files)\n",
    "#targets = np.array(targets)\n",
    "#\n",
    "#dataset = ProteinDataset(processed_dir, raw_files, targets, overwrite=False)\n",
    "#\n",
    "## init proteinsolver gnn\n",
    "#num_features = 20\n",
    "#adj_input_size = 2\n",
    "#hidden_size = 128\n",
    "#\n",
    "#gnn = Net(\n",
    "#    x_input_size=num_features + 1, \n",
    "#    adj_input_size=adj_input_size, \n",
    "#    hidden_size=hidden_size, \n",
    "#    output_size=num_features\n",
    "#)\n",
    "#gnn.load_state_dict(torch.load(state_file, map_location=device))\n",
    "#gnn.eval()\n",
    "#gnn = gnn.to(device)\n",
    "#\n",
    "## init LSTM\n",
    "#num_classes = 3\n",
    "#num_layers = 2\n",
    "#hidden_size = 26\n",
    "#\n",
    "#net = MyLSTM(num_classes, num_features, num_layers, hidden_size)\n",
    "#net = net.to(device)\n",
    "#\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.0001) \n",
    "#\n",
    "## training params\n",
    "#epochs = 1\n",
    "#n_splits = 5\n",
    "#batch_size = 5\n",
    "#\n",
    "## touch files to ensure output\n",
    "#save_dir = get_non_dupe_dir(out_dir)\n",
    "#loss_paths = touch_output_files(save_dir, \"loss\", n_splits)\n",
    "#state_paths = touch_output_files(save_dir, \"state\", n_splits)\n",
    "#pred_paths = touch_output_files(save_dir, \"pred\", n_splits)\n",
    "#\n",
    "#CV = KFold(n_splits=n_splits, shuffle=True)\n",
    "#i = 0\n",
    "#for train_idx, valid_idx in CV.split(dataset):\n",
    "#    \n",
    "#    train_subset = dataset[torch.LongTensor(train_idx)][0:10]\n",
    "#    valid_subset = dataset[torch.LongTensor(valid_idx)][0:10]\n",
    "#    \n",
    "#    net = MyLSTM(num_classes, num_features, num_layers, hidden_size)\n",
    "#    net = net.to(device)\n",
    "#    \n",
    "#    # partial function - gnn arg is static, x is given later\n",
    "#    gnn_transform = lambda x: gnn_to_lstm_batch(\n",
    "#        x, \n",
    "#        gnn_instance=gnn, \n",
    "#        device=device,\n",
    "#        num_classes=num_classes\n",
    "#)\n",
    "#    \n",
    "#    net, train_subset_losses, valid_subset_losses = train_model(\n",
    "#        model=net,\n",
    "#        epochs=epochs, \n",
    "#        criterion=criterion,\n",
    "#        optimizer=optimizer,\n",
    "#        train_data=train_subset, \n",
    "#        valid_data=valid_subset,\n",
    "#        batch_size=batch_size,\n",
    "#        device=device,\n",
    "#        transform=gnn_transform,\n",
    "#)\n",
    "#\n",
    "#    torch.save({\"train\": train_subset_losses, \"valid\": valid_subset_losses}, loss_paths[i])\n",
    "#    torch.save(net.state_dict(), state_paths[i])\n",
    "#    \n",
    "#    # perform test preds\n",
    "#    y_pred, y_true = predict(\n",
    "#        model=net, \n",
    "#        data=train_subset, \n",
    "#        batch_size=batch_size,\n",
    "#        device=device,\n",
    "#        transform=gnn_transform,\n",
    "#)\n",
    "#\n",
    "#    torch.save({\"y_pred\": y_pred, \"y_true\": y_true,}, pred_paths[i])\n",
    "#    \n",
    "#    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64886378",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #annotations = train_subset.dataset.annotations.squeeze(1)\n",
    "    #class_weights = compute_class_weight(\n",
    "    #    'balanced',\n",
    "    #    np.unique(annotations),\n",
    "    #    annotations.numpy()\n",
    "    #)\n",
    "    #class_weights = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def pad_collate_chain_split(batch, pad_val=0):\n",
    "#    (xx, yy) = zip(*batch)\n",
    "#    x_1_batch = list()\n",
    "#    x_2_batch = list()\n",
    "#    x_3_batch = list()\n",
    "#    x_4_batch = list()\n",
    "#    for x in xx:\n",
    "#        x_1_batch.append(x[x[:,-1] == 1][:,:-4])  # slice based on positional encoding and remove encoding part\n",
    "#        x_2_batch.append(x[x[:,-2] == 1][:,:-4])\n",
    "#        x_3_batch.append(x[x[:,-3] == 1][:,:-4])\n",
    "#        x_4_batch.append(x[x[:,-4] == 1][:,:-4])\n",
    "#\n",
    "#    x1_pad = nn.utils.rnn.pad_sequence(x_1_batch, batch_first=True, padding_value=pad_val)\n",
    "#    x2_pad = nn.utils.rnn.pad_sequence(x_2_batch, batch_first=True, padding_value=pad_val)\n",
    "#    x3_pad = nn.utils.rnn.pad_sequence(x_3_batch, batch_first=True, padding_value=pad_val)\n",
    "#    x4_pad = nn.utils.rnn.pad_sequence(x_4_batch, batch_first=True, padding_value=pad_val)\n",
    "#    yy_pad = nn.utils.rnn.pad_sequence(yy, batch_first=True, padding_value=pad_val)\n",
    "#    return (x1_pad, x2_pad, x3_pad, x4_pad), yy_pad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32218ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_train(\n",
    "    model,\n",
    "    epochs,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataset,\n",
    "    train_idx, \n",
    "    valid_idx,\n",
    "    batch_size,\n",
    "    device,\n",
    "):\n",
    "    train_losses = list()\n",
    "    valid_losses = list()\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        train_loader = DataLoader(dataset=dataset, batch_size=batch_size, collate_fn=pad_collate)\n",
    "        valid_loader = DataLoader(dataset=dataset, batch_size=batch_size, collate_fn=pad_collate)\n",
    "\n",
    "        train_len = len(train_loader)\n",
    "        valid_len = len(valid_loader)\n",
    "\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        j = 0\n",
    "        for x, y, _, _ in train_loader:    \n",
    "            y = y.to(device)\n",
    "            x = x.to(device)\n",
    "            y_pred = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            display_func(j, train_len, e, train_losses, valid_losses)\n",
    "            j += 1\n",
    "            \n",
    "        valid_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x, y, _, _ in valid_loader:    \n",
    "                y = y.to(device)\n",
    "                x = x.to(device)\n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        train_losses.append(train_loss / train_len)\n",
    "        valid_losses.append(valid_loss / valid_len)\n",
    "\n",
    "    return model, train_losses, valid_losses\n",
    "\n",
    "\n",
    "def lstm_predict(model, dataset, idx, device):\n",
    "    data_loader = DataLoader(dataset=dataset, sampler=idx, batch_size=1, shuffle=False, collate_fn=pad_collate)\n",
    "    pred = list()\n",
    "    true = list()\n",
    "    with torch.no_grad():\n",
    "        for x, y, _, _ in data_loader:    \n",
    "            y = y.to(device)\n",
    "            x = x.to(device)\n",
    "            y_pred = model(x)\n",
    "            pred.append(torch.sigmoid(y_pred))\n",
    "            true.append(y)\n",
    "    return torch.Tensor(pred), torch.Tensor(true)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
