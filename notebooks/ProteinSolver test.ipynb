{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90ffe2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch_geometric\n",
    "import kmbio  # fork of biopython PDB with some changes in how the structure, chain, etc. classes are defined.\n",
    "import numpy as np\n",
    "import proteinsolver\n",
    "\n",
    "from proteinsolver.models.model import *\n",
    "from proteinsolver.datasets import *\n",
    "\n",
    "# custom stuff\n",
    "#import proteinsolver_utils\n",
    "#import proteinsolver_datasets\n",
    "np.random.seed(1)\n",
    "\n",
    "sys.path.append('/home/sebastian/masters/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82700821",
   "metadata": {},
   "source": [
    "### Parameter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "605fd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_ID = \"191f05de\"\n",
    "BEST_STATE_FILES = {\n",
    "    #\n",
    "    \"191f05de\": \"/home/sebastian/proteinsolver/data/e53-s1952148-d93703104.state\"\n",
    "}\n",
    "state_file = BEST_STATE_FILES[UNIQUE_ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f40f8d",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20e59247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from modules.dataset import *\n",
    "\n",
    "\n",
    "raw_files, targets = get_data(\"/home/sebastian/masters/data/210916_TCRpMHCmodels/\")\n",
    "root = \"/home/sebastian/masters/data/210916_TCRpMHCmodels/\"\n",
    "\n",
    "# make quick data split\n",
    "n_data = len(raw_files)\n",
    "valid_frac = 0.1\n",
    "valid_num = int(n_data * valid_frac)\n",
    "selection = np.random.randint(0, n_data, valid_num)\n",
    "mask = np.zeros(n_data, bool)\n",
    "mask[selection] = 1\n",
    "\n",
    "valid_files = raw_files[mask]\n",
    "valid_targets = targets[mask]\n",
    "d_valid = ProteinDataset(f\"{root}/valid\", valid_files, valid_targets, overwrite=False)\n",
    "\n",
    "train_files = raw_files[~mask]\n",
    "train_targets = targets[~mask]\n",
    "d_train = ProteinDataset(f\"{root}/train\", train_files, train_targets, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80445a82",
   "metadata": {},
   "source": [
    "### Init proteinsolver network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "071f751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_features = 20\n",
    "adj_input_size = 2\n",
    "hidden_size = 128\n",
    "#frac_present = 0.5\n",
    "#frac_present_valid = frac_present\n",
    "#info_size= 1024\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gnn = Net(\n",
    "    x_input_size=num_features + 1, adj_input_size=adj_input_size, hidden_size=hidden_size, output_size=num_features\n",
    ")\n",
    "gnn.load_state_dict(torch.load(state_file, map_location=device))\n",
    "gnn.eval()\n",
    "gnn = gnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0ad9c",
   "metadata": {},
   "source": [
    "### Init classifier network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27e47f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_features = 20\n",
    "epochs = 1\n",
    "\n",
    "class TestNet(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool1d(  # https://stackoverflow.com/a/63603993/11398318\n",
    "            output_size=hidden_size\n",
    "        ) \n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(hidden_size * num_features, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        x = x.T.flatten()\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "net = TestNet(50)\n",
    "net = net.to(device)\n",
    "save_path = \"/home/sebastian/masters/data/trained_models/test_model.state\"\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecb50f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \ttrain_loss: 0.33302355 \tvalid_loss: 0.58643964\n"
     ]
    }
   ],
   "source": [
    "from modules.utils import *\n",
    "\n",
    "train_losses = list()\n",
    "valid_losses = list()\n",
    "\n",
    "print(f\"Training for {epochs} epochs:\")\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loader = iter(torch_geometric.data.DataLoader(d_train, batch_size=batch_size))\n",
    "    valid_loader = iter(torch_geometric.data.DataLoader(d_valid, batch_size=batch_size))\n",
    "    \n",
    "    train_len = len(train_loader)\n",
    "    valid_len = len(valid_loader)\n",
    "    \n",
    "    train_loss = 0\n",
    "    net.train()\n",
    "    for j, x in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        y = torch.Tensor(x.y)\n",
    "        with torch.no_grad():\n",
    "            x = gnn(x.x, x.edge_index, x.edge_attr)\n",
    "        out = net(x.T.unsqueeze(0))\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        display_func(j, train_len, i, train_losses, valid_losses)\n",
    "        \n",
    "    valid_loss = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for x in valid_loader:\n",
    "            x = x.to(device)\n",
    "            y = torch.Tensor(x.y)\n",
    "            x = gnn(x.x, x.edge_index, x.edge_attr)\n",
    "            out = net(x.T.unsqueeze(0))\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss / train_len)\n",
    "    valid_losses.append(valid_loss / valid_len)\n",
    "    \n",
    "print_loss(train_losses, valid_losses, clear_print=True)\n",
    "\n",
    "torch.save(net.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c82c13",
   "metadata": {},
   "source": [
    "### Visualization and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcaf6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d_test = d_valid\n",
    "test_loader = iter(torch_geometric.data.DataLoader(d_test, batch_size=1))\n",
    "\n",
    "net.load_state_dict(torch.load(save_path))\n",
    "net.eval()\n",
    "\n",
    "pred = list()\n",
    "y = list()\n",
    "with torch.no_grad():\n",
    "        for x in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = x.y\n",
    "            x = gnn(x.x, x.edge_index, x.edge_attr)\n",
    "            out = torch.sigmoid(net(x.T.unsqueeze(0)))\n",
    "            pred.append(out.item())\n",
    "            y.append(y[0])\n",
    "\n",
    "pred = np.array(pred)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d72bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_range = list(range(epochs))\n",
    "plt.plot(epoch_range, train_losses, '-')\n",
    "plt.plot(epoch_range, valid_losses, '-')\n",
    "plt.legend([\"Training loss\", \"Validation loss\"])\n",
    "plt.title(\"Binary cross-entropy loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"BCE loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd894750",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, '-')\n",
    "plt.legend([f\"AUC = {round(auc, 5)}\"])\n",
    "plt.title(\"ROC curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fc9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
